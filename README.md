**A brief preface:** This repository has been refactored from a single project into a collection of small projects, each showcasing best practices in the field of ML classification with classic ML and Deep Learning models as well.

This README file provides brief information about each notebook or folder, outlining their respective task solutions.
--

`mushrooms_classification.ipynb` contains the implementation of EDA, feature engineering, modeling with classical ML algorithms, and subsequent best model validation. Data source for this small project was UC Irvine Machine Learning Repository with [mushroom dataset](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset). Detailed report with conclusions available [here](https://github.com/elch1k/ml_classification_approaches/blob/main/mushrooms_classification.ipynb).

In imbalanced_classification.ipynb, various techniques were implemented to address imbalanced classes. These include undersampling (NearMiss), oversampling (SMOTE, ADASYN), Tomek Links, ensemble methods with undersampling, and the correction of class weights. An Artificial Neural Network (ANN) was also implemented using the SMOTE method. The dataset used was obtained from Kaggle's Bank Turnover Dataset, available [here](https://www.kaggle.com/datasets/barelydedicated/bank-customer-churn-modeling). The report and implementation can be accessed [here](https://github.com/elch1k/ml_classification_approaches/blob/main/imbalanced_classification.ipynb).
